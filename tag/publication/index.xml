<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publication | Jonathan CrabbÃ©</title>
    <link>https://jonathancrabbe.github.io/tag/publication/</link>
      <atom:link href="https://jonathancrabbe.github.io/tag/publication/index.xml" rel="self" type="application/rss+xml" />
    <description>Publication</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 08 Jun 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://jonathancrabbe.github.io/media/icon_hudf155d04df3b15b0b3080a45aba6eb0e_2672_512x512_fill_lanczos_center_3.png</url>
      <title>Publication</title>
      <link>https://jonathancrabbe.github.io/tag/publication/</link>
    </image>
    
    <item>
      <title>2 Papers Accepted at ICML 2022</title>
      <link>https://jonathancrabbe.github.io/post/icml2022_two_papers/</link>
      <pubDate>Wed, 08 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/post/icml2022_two_papers/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m extremely excited to present 2 works at &lt;a href=&#34;https://icml.cc/Conferences/2022&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ICML 2022&lt;/a&gt;  ðŸŽ‰
They touch on various subjects ranging from explainable AI to robust and data-centric machine learning.
Unfortunately, I will be unable to attend the conference in person. Hence, do not miss the opportunity to interact with me during the online sessions. I&amp;rsquo;m always enthusiastic to engage and discuss these fascinating subjects ðŸ˜„
I will post the relevant practical information &lt;a href=&#34;https://jonathancrabbe.github.io/talk/2-spotlight-presentations-at-icml-2022/&#34;&gt;on this page&lt;/a&gt; once they are available. Stay tuned ðŸ“»&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-label-free-explainability&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /post/icml2022_two_papers/lfxai_hu9d7bb4484dcaaebbc3e8baff9f352678_466108_89e9bb33d25769614b7a08fbf82f2e25.webp 400w,
               /post/icml2022_two_papers/lfxai_hu9d7bb4484dcaaebbc3e8baff9f352678_466108_0a1f2819aca0df0ae399e6b3381e6c41.webp 760w,
               /post/icml2022_two_papers/lfxai_hu9d7bb4484dcaaebbc3e8baff9f352678_466108_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://jonathancrabbe.github.io/post/icml2022_two_papers/lfxai_hu9d7bb4484dcaaebbc3e8baff9f352678_466108_89e9bb33d25769614b7a08fbf82f2e25.webp&#34;
               width=&#34;760&#34;
               height=&#34;358&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Label-Free Explainability
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jonathancrabbe.github.io/publication/lfxai/&#34;&gt;Label-Free Explainability&lt;/a&gt; is a new framework to extend feature and example importance methods to the unsupervised setting. If you have always dreamed to use SHAP or Influence Functions to explain the representations of your brand-new encoder, this paper is for you!&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-data-suite&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /post/icml2022_two_papers/data-suite_huae2701e9fdebdc4be2dcf287e405f358_102282_94ab3f23cda9e90fd4ddc5bf5f88a990.webp 400w,
               /post/icml2022_two_papers/data-suite_huae2701e9fdebdc4be2dcf287e405f358_102282_a591e3116f04640190e4a3da93efa18a.webp 760w,
               /post/icml2022_two_papers/data-suite_huae2701e9fdebdc4be2dcf287e405f358_102282_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://jonathancrabbe.github.io/post/icml2022_two_papers/data-suite_huae2701e9fdebdc4be2dcf287e405f358_102282_94ab3f23cda9e90fd4ddc5bf5f88a990.webp&#34;
               width=&#34;760&#34;
               height=&#34;184&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Data-SUITE
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jonathancrabbe.github.io/publication/data_suite/&#34;&gt;Data-SUITE&lt;/a&gt; is a data-centric method to flag incongruous examples at inference time. If you want to avoid using your machine learning model on data that differs too much from the training data, you might want to take a look!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
