<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jonathan Crabbé</title>
    <link>https://jonathancrabbe.github.io/</link>
      <atom:link href="https://jonathancrabbe.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Jonathan Crabbé</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 09 Mar 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://jonathancrabbe.github.io/media/icon_hudf155d04df3b15b0b3080a45aba6eb0e_2672_512x512_fill_lanczos_center_3.png</url>
      <title>Jonathan Crabbé</title>
      <link>https://jonathancrabbe.github.io/</link>
    </image>
    
    <item>
      <title>TANGOS: Regularizing Tabular Neural Networks through Gradient Orthogonalization and Specialization</title>
      <link>https://jonathancrabbe.github.io/publication/tangos/</link>
      <pubDate>Thu, 09 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/publication/tangos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Concept Activation Regions: A Generalized Framework For Concept-Based Explanations</title>
      <link>https://jonathancrabbe.github.io/publication/car/</link>
      <pubDate>Thu, 15 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/publication/car/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Data-IQ: Characterizing subgroups with heterogeneous outcomes in tabular data</title>
      <link>https://jonathancrabbe.github.io/publication/data_iq/</link>
      <pubDate>Thu, 15 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/publication/data_iq/</guid>
      <description></description>
    </item>
    
    <item>
      <title>2 Spotlight Presentations at ICML 2022</title>
      <link>https://jonathancrabbe.github.io/talk/2-spotlight-presentations-at-icml-2022/</link>
      <pubDate>Sun, 17 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/talk/2-spotlight-presentations-at-icml-2022/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://jonathancrabbe.github.io/publication/lfxai/&#34;&gt;Label-Free Explainability.&lt;/a&gt; The timing is available on &lt;a href=&#34;https://icml.cc/Conferences/2022/Schedule?showEvent=16184&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jonathancrabbe.github.io/publication/lfxai/&#34;&gt;Data-SUITE.&lt;/a&gt; The timing is available on &lt;a href=&#34;https://icml.cc/Conferences/2022/Schedule?showEvent=17080&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this page&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Benchmarking Heterogeneous Treatment Effect Models through the Lens of Interpretability</title>
      <link>https://jonathancrabbe.github.io/publication/iterpretability/</link>
      <pubDate>Thu, 16 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/publication/iterpretability/</guid>
      <description></description>
    </item>
    
    <item>
      <title>2 Papers Accepted at ICML 2022</title>
      <link>https://jonathancrabbe.github.io/post/icml2022_two_papers/</link>
      <pubDate>Wed, 08 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/post/icml2022_two_papers/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m extremely excited to present 2 works at &lt;a href=&#34;https://icml.cc/Conferences/2022&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ICML 2022&lt;/a&gt;  🎉
They touch on various subjects ranging from explainable AI to robust and data-centric machine learning.
Unfortunately, I will be unable to attend the conference in person. Hence, do not miss the opportunity to interact with me during the online sessions. I&amp;rsquo;m always enthusiastic to engage and discuss these fascinating subjects 😄
I will post the relevant practical information &lt;a href=&#34;https://jonathancrabbe.github.io/talk/2-spotlight-presentations-at-icml-2022/&#34;&gt;on this page&lt;/a&gt; once they are available. Stay tuned 📻&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-label-free-explainability&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /post/icml2022_two_papers/lfxai_hu9d7bb4484dcaaebbc3e8baff9f352678_466108_89e9bb33d25769614b7a08fbf82f2e25.webp 400w,
               /post/icml2022_two_papers/lfxai_hu9d7bb4484dcaaebbc3e8baff9f352678_466108_0a1f2819aca0df0ae399e6b3381e6c41.webp 760w,
               /post/icml2022_two_papers/lfxai_hu9d7bb4484dcaaebbc3e8baff9f352678_466108_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://jonathancrabbe.github.io/post/icml2022_two_papers/lfxai_hu9d7bb4484dcaaebbc3e8baff9f352678_466108_89e9bb33d25769614b7a08fbf82f2e25.webp&#34;
               width=&#34;760&#34;
               height=&#34;358&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Label-Free Explainability
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jonathancrabbe.github.io/publication/lfxai/&#34;&gt;Label-Free Explainability&lt;/a&gt; is a new framework to extend feature and example importance methods to the unsupervised setting. If you have always dreamed to use SHAP or Influence Functions to explain the representations of your brand-new encoder, this paper is for you!&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-data-suite&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /post/icml2022_two_papers/data-suite_huae2701e9fdebdc4be2dcf287e405f358_102282_94ab3f23cda9e90fd4ddc5bf5f88a990.webp 400w,
               /post/icml2022_two_papers/data-suite_huae2701e9fdebdc4be2dcf287e405f358_102282_a591e3116f04640190e4a3da93efa18a.webp 760w,
               /post/icml2022_two_papers/data-suite_huae2701e9fdebdc4be2dcf287e405f358_102282_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://jonathancrabbe.github.io/post/icml2022_two_papers/data-suite_huae2701e9fdebdc4be2dcf287e405f358_102282_94ab3f23cda9e90fd4ddc5bf5f88a990.webp&#34;
               width=&#34;760&#34;
               height=&#34;184&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Data-SUITE
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jonathancrabbe.github.io/publication/data_suite/&#34;&gt;Data-SUITE&lt;/a&gt; is a data-centric method to flag incongruous examples at inference time. If you want to avoid using your machine learning model on data that differs too much from the training data, you might want to take a look!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Label-Free Explainability for Unsupervised Models</title>
      <link>https://jonathancrabbe.github.io/publication/lfxai/</link>
      <pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/publication/lfxai/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Representation Learning</title>
      <link>https://jonathancrabbe.github.io/project/repl/</link>
      <pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/project/repl/</guid>
      <description>&lt;p&gt;How can we make sure that machines learn a good representation of the data? If labelling the data is a typical solution, it is often costly and time-consuming. Models such as neural networks typically require thousands to millions of examples to solve a task. Is it possible to learn good representations of the data without having to label each one of these examples?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Representation Learning&lt;/em&gt; provides interesting solutions through semi-supervised and self-supervised learning. With these techniques, it becomes increasingly realistic to solve complex tasks with few labelled examples. In some cases, we might want these representations to be understandable by human users. This induces a significant overlap with &lt;a href=&#34;https://jonathancrabbe.github.io/project/xai/&#34;&gt;Explainable Artificial Intelligence&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data-SUITE: Data-centric identification of in-distribution incongruous examples</title>
      <link>https://jonathancrabbe.github.io/publication/data_suite/</link>
      <pubDate>Thu, 17 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/publication/data_suite/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Robust Machine Learning</title>
      <link>https://jonathancrabbe.github.io/project/rml/</link>
      <pubDate>Thu, 17 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/project/rml/</guid>
      <description>&lt;p&gt;How can we make a machine learning model reliable? If generalization to unseen data is undoubtedly necessary, it is rarely sufficient. Models such as neural networks typically involve millions of operations to turn their input data into a prediction. This complexity permits to solve hard problems like computer vision and protein structure prediction. However, these complex models tend to exhibit unpredictable behaviours, such as the sensitivity to adversarial perturbations and spurious correlations . When models penetrate critical areas such as medicine, finance and the criminal justice system, this unpredictability is highly problematic.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Robust machine learning&lt;/em&gt; tackles this problem by providing tools to identify and fix the weaknesses of a model. This includes (but is not limited to) understanding the model&amp;rsquo;s failure modes, quantifying the model&amp;rsquo;s uncertainty and teaching a model to be robust with respect to noise/adversarial perturbations. With the development of Data-Centric AI, I believe that many new and exciting things can be done in this area.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DAUX: a Density-based Approach for Uncertainty eXplanations</title>
      <link>https://jonathancrabbe.github.io/publication/daux/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/publication/daux/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Explaining Latent Representations with a Corpus of Examples</title>
      <link>https://jonathancrabbe.github.io/publication/simplex/</link>
      <pubDate>Wed, 17 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/publication/simplex/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Explaining Time Series Predictions with Dynamic Masks</title>
      <link>https://jonathancrabbe.github.io/publication/dynamask/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/publication/dynamask/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning outside the black-box: the pursuit of interpretable models</title>
      <link>https://jonathancrabbe.github.io/publication/symbolic_pursuit/</link>
      <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/publication/symbolic_pursuit/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Explainable Artificial Intelligence</title>
      <link>https://jonathancrabbe.github.io/project/xai/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/project/xai/</guid>
      <description>&lt;p&gt;How can we make a machine learning model convincing? If accuracy is undoubtedly necessary, it is rarely sufficient. Models such as neural networks typically involve millions of operations to turn their input data into a prediction. This complexity permits to accurately solve hard problems like computer vision and protein structure prediction. However, this accuracy comes at the expense of interpretability: these complex models appear as black boxes for human users. When models penetrate critical areas such as medicine, finance and the criminal justice system, their black-box nature appears as a major issue. An important question follows: is it possible to explain the predictions of complex machine-learning models?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Explainable AI&lt;/em&gt; tackles this question by providing an interface between complex models and human users. To illustrate, let us consider the example of a medical machine learning model that recommends a treatment for a patient. By using post-hoc explainability, we can answer crucial questions such as “What part of this patient’s data motivates the model’s recommendation?” or “Are there similar patients previously seen by the model for which this treatment worked?”. In a setting where human knowledge is available (e.g. computer vision), this type of information is crucial to validate/debug the model. In a setting where little human knowledge (e.g. scientific discovery), this type of information permits to extract knowledge from the model.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://jonathancrabbe.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://revealjs.com/pdf-export/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Eating...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
  One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  Three
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Only the speaker can read these notes
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Press &lt;span class=&#34;sb&#34;&gt;`S`&lt;/span&gt; key to view
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {{% /speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/media/boards.jpg&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;#0000FF&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;my-style&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-css&#34; data-lang=&#34;css&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h3&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;navy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://jonathancrabbe.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://jonathancrabbe.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
